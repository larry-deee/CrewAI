{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!pip install crewai\n",
        "!pip install 'crewai[tools]'\n",
        "!pip install google-api-python-client\n",
        "!pip install langchain-openai\n"
      ],
      "metadata": {
        "id": "YF5OUPTIAge0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import our API Keys\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Keys\n",
        "os.environ[\"SERPER_API_KEY\"] = userdata.get('SERPER_API_KEY')\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"GOOGLE_CSE_ID\"] = userdata.get('GOOGLE_CSE_ID')  # Google Custom Search Engine ID\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "nQEpfwRuAQ6s"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the Topic Here\n",
        "#######\n",
        "search_query = \"\"\"\n",
        "Demystifing Autonomous AI Agents in the Digital Age.\n",
        "\"\"\"\n",
        "####"
      ],
      "metadata": {
        "id": "4v70Nm30DtVd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsapJFG9_mYq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from googleapiclient.discovery import build\n",
        "from crewai import Agent, Task, Crew, Process\n",
        "from langchain_openai import ChatOpenAI\n",
        "from crewai_tools import WebsiteSearchTool, ScrapeWebsiteTool\n",
        "\n",
        "\n",
        "# Define Google Search Tool\n",
        "class GoogleSearchTool:\n",
        "    def __init__(self, api_key, cse_id):\n",
        "        if not api_key or not cse_id:\n",
        "            raise ValueError(\"API key and CSE ID must be provided\")\n",
        "\n",
        "        # Initialize the Google Custom Search API client\n",
        "        self.api_key = api_key\n",
        "        self.cse_id = cse_id\n",
        "        self.service = build(\"customsearch\", \"v1\", developerKey=self.api_key)\n",
        "        self.name = \"GoogleSearchTool\"\n",
        "        self.args = {\"query\": \"Search term to find relevant results\"}\n",
        "        self.description = \"Performs a Google search and returns relevant results.\"\n",
        "\n",
        "    def search(self, query, num_results=5):\n",
        "        if not query or not isinstance(query, str):\n",
        "            return \"Error: Invalid query provided.\"\n",
        "\n",
        "        try:\n",
        "            # Execute the search query\n",
        "            results = self.service.cse().list(q=query, cx=self.cse_id, num=num_results).execute()\n",
        "            items = results.get('items', [])\n",
        "            return [\n",
        "                {\"title\": item.get('title', 'No title'), \"url\": item.get('link', 'No link'), \"snippet\": item.get('snippet', 'No snippet')}\n",
        "                for item in items\n",
        "            ]\n",
        "        except Exception as e:\n",
        "            return f\"Error during search: {str(e)}\"\n",
        "\n",
        "        # Add invoke method to handle CrewAI's expectations\n",
        "    def invoke(self, input=None):\n",
        "        try:\n",
        "            # Parse the input, it is expected to be a JSON string or dict\n",
        "            input_data = json.loads(input) if isinstance(input, str) else input\n",
        "            query = input_data.get(\"query\")\n",
        "\n",
        "            if not query:\n",
        "                return \"Error: No query provided.\"\n",
        "\n",
        "            # Perform the search\n",
        "            results = self.search(query)\n",
        "            return json.dumps(results, indent=2)\n",
        "        except json.JSONDecodeError:\n",
        "            return \"Error: Failed to parse input as JSON.\"\n",
        "        except Exception as e:\n",
        "            return f\"Error: {str(e)}\"\n",
        "\n",
        "\n",
        "# Define the Research Agent\n",
        "class ResearchAgent(Agent):\n",
        "    def __init__(self, name, role, goal, backstory, tools):\n",
        "        super().__init__(name=name, role=role, goal=goal, backstory=backstory, tools=tools)\n",
        "\n",
        "    # Method to process search results and extract key insights\n",
        "    def process_search_results(self, search_results):\n",
        "        insights = []\n",
        "        for result in search_results:\n",
        "            insights.append(f\"Title: {result['title']}\\nSummary: {result['snippet']}\\nURL: {result['link']}\")\n",
        "        return \"\\n\".join(insights)\n",
        "\n",
        "\n",
        "# Initialize Google Search Tool with API keys\n",
        "google_search_tool = GoogleSearchTool(\n",
        "    api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
        "    cse_id=os.getenv(\"GOOGLE_CSE_ID\")\n",
        ")\n",
        "\n",
        "# Define Agents\n",
        "researcher = ResearchAgent(\n",
        "    name='Principal Researcher and Analyst',\n",
        "    role='Researcher',\n",
        "    goal=f\"Uncover cutting-edge developments in {search_query} and related topics.\",\n",
        "    backstory=\"\"\"\n",
        "        You are an experienced and award-winning researcher who excels at finding actionable insights\n",
        "        and translating complex data into engaging content.\n",
        "    \"\"\",\n",
        "    tools=[google_search_tool, ScrapeWebsiteTool()]\n",
        ")\n",
        "\n",
        "writer = Agent(\n",
        "    role='Tech Content Strategist',\n",
        "    goal=f\"Craft compelling content on {search_query} advancements.\",\n",
        "    backstory=\"\"\"\n",
        "      You are a renowned Content Strategist known for translating complex ideas into engaging narratives.\n",
        "    \"\"\",\n",
        "    verbose=True,\n",
        "    allow_delegation=True,\n",
        "    llm=ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.7)\n",
        ")\n",
        "\n",
        "# Define Tasks\n",
        "def researcher_task_execution():\n",
        "    # Researcher performs the search and processes the results\n",
        "    # search_query = \"The latest trends in AI and Data Analytics 2024\"\n",
        "    search_results = google_search_tool.search(query=search_query)\n",
        "\n",
        "    # Researcher processes search results to extract insights\n",
        "    processed_insights = researcher.process_search_results(search_results)\n",
        "\n",
        "    # Save processed insights to a file (or return for next task)\n",
        "    with open(\"researcher_tasks.md\", \"w\") as file:\n",
        "        file.write(processed_insights)\n",
        "\n",
        "    return processed_insights\n",
        "\n",
        "\n",
        "# Research Task: Perform the search, process the results, and save insights\n",
        "research = Task(\n",
        "    description=f\"\"\"\n",
        "      Extract key insights, ideas, and information from {search_query}.\n",
        "    \"\"\",\n",
        "    expected_output=f\"\"\"\n",
        "      A concise report on {search_query}, containing key insights and recommendations in bullet points.\n",
        "    \"\"\",\n",
        "    agent=researcher,\n",
        "    output_file=\"researcher_tasks.md\",\n",
        "    execution_function=researcher_task_execution  # Executes the researcher's function to gather insights\n",
        ")\n",
        "\n",
        "\n",
        "# Writing Task: Use the processed insights to write a blog post\n",
        "def writer_task_execution(context):\n",
        "    # Retrieve the insights from the previous research task (context)\n",
        "    insights = context  # passed from research task\n",
        "\n",
        "    # Writer generates the blog post using insights\n",
        "    blog_post = f\"\"\"\n",
        "    # {search_query}\n",
        "\n",
        "    In this blog, we explore the latest trends:\n",
        "\n",
        "    {insights}\n",
        "\n",
        "    Stay tuned for more cutting-edge developments.\n",
        "    \"\"\"\n",
        "\n",
        "    # Return the blog post (CrewAI will handle saving to output_file)\n",
        "    return blog_post\n",
        "\n",
        "\n",
        "write_blog = Task(\n",
        "    description=f\"\"\"\n",
        "    Thought: Review the research findings on {search_query} and think about how to structure an engaging blog post.\n",
        "    Action: Use the research data to write a compelling 800-word blog post, including relevant citations from the URLs provided in the research.\n",
        "    Observation: Make sure the post is coherent, flows well, and stays on topic. Ensure all URLs are properly cited.\n",
        "    \"\"\",\n",
        "    expected_output=\"\"\"\n",
        "      A full blog post of around 800 words with citations from all the URLs.\n",
        "    \"\"\",\n",
        "    agent=writer,\n",
        "    context=[research],  # Use the output of the research task as context\n",
        "    output_file=\"writer_tasks.md\",  # CrewAI will save the blog post to this file\n",
        "    execution_function=writer_task_execution\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Instantiate the Crew and kick off the process\n",
        "crew = Crew(\n",
        "    agents=[researcher, writer],\n",
        "    tasks=[research, write_blog],\n",
        "    verbose=True,\n",
        "    process=Process.sequential  # Ensure the research task finishes before writing starts\n",
        ")\n",
        "\n",
        "# Kickoff the crew process\n",
        "result = crew.kickoff()\n",
        "\n",
        "# Print the result (final blog post)\n",
        "print(result)\n"
      ]
    }
  ]
}